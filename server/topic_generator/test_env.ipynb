{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273357c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim import corpora, models\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from typing import Dict\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import RootModel\n",
    "import os\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "\n",
    "class TopicNames(RootModel[Dict[str, str]]):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "class TopicAgent:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",api_key=api_key)\n",
    "        self.context_prompt = (\n",
    "            \"You are a market intelligence expert and trend analyst in science and technology. \"\n",
    "        )\n",
    "\n",
    "\n",
    "    def Generate_names(self, topic_string: str) -> str:\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=self.context_prompt),\n",
    "            (\"Your task is to analyze the output of an LDA model and assign meaningful, short, and descriptive names \"\n",
    "            \"to each topic based on its keywords. \"\n",
    "            \"Return your output STRICTLY as a valid JSON object mapping the topic ID to its name.\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"{{\\n\"\n",
    "            \"  'topic 1': 'topic name',\\n\"\n",
    "            \"  'topic 2': 'topic name'\\n\"\n",
    "            \"}}\\n\"),\n",
    "            (\"human\", \"Generate topic names considering this output: {topic_string}\")\n",
    "        ])\n",
    "\n",
    "\n",
    "        topic_chain = prompt | self.llm | PydanticOutputParser(pydantic_object=TopicNames)\n",
    "        result = topic_chain.invoke({\"topic_string\": topic_string})\n",
    "        return result.root\n",
    "    \n",
    "    def Generate_summary(self, topic_string: str) -> str:\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=self.context_prompt),\n",
    "            (\"Your task is to analyze a topic name for a give category and the titles from the articles that belong to this category\"\n",
    "            \" and write a small descriptive summary to understant site visitors to understand what that topic is about \"\n",
    "            ),\n",
    "            (\"human\", \"Generate text considering this this informations: {topic_string}\")\n",
    "        ])\n",
    "\n",
    "\n",
    "        topic_chain = prompt | self.llm | StrOutputParser()\n",
    "        result = topic_chain.invoke({\"topic_string\": topic_string})\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA_handler():\n",
    "    def __init__(self,csv_file):\n",
    "        self.data_src = csv_file\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.classify_agent = TopicAgent()\n",
    "\n",
    "    def Generate_article_text_list(self):\n",
    "        return self.df['Title'].tolist()\n",
    "\n",
    "    def Generate_tokenized_list(self,text_list):\n",
    "        return [\n",
    "            [word for word in text.lower().split() if word not in STOPWORDS]\n",
    "            for text in text_list\n",
    "        ]\n",
    "\n",
    "    def Transform_data_numeric(self,tokens_list):\n",
    "        dictionary = corpora.Dictionary(tokens_list)\n",
    "        corpus = [dictionary.doc2bow(text) for text in tokens_list]\n",
    "        return dictionary, corpus\n",
    "    \n",
    "    def Generate_lda_model(self,topics_number,corpus,dictionary,passes):\n",
    "        lda_model = models.LdaModel(corpus, num_topics=topics_number, id2word=dictionary, passes=passes, random_state=42)  \n",
    "        return lda_model\n",
    "\n",
    "    def Get_lda_topics_keywords(self, lda_model):\n",
    "        result = \"\"\n",
    "        for i in range(lda_model.num_topics):\n",
    "            topic_text = f\"topic {i}: {lda_model.print_topic(i)}\\n\"\n",
    "            result += topic_text\n",
    "        return result\n",
    "\n",
    "    def Append_model_to_df(self,lda_model,corpus):\n",
    "        title_topics = []\n",
    "        for doc_bow in corpus:\n",
    "            title_topics.append(lda_model.get_document_topics(doc_bow))\n",
    "\n",
    "        self.df['topics'] = title_topics\n",
    "\n",
    "    def Create_model_names(self,topics_keywords):\n",
    "        return self.classify_agent.Generate_names(topics_keywords)\n",
    "\n",
    "    def Get_all_titles_from_topic(self, topic_num, threshold=0.4):\n",
    "\n",
    "        def topic_greater_than_threshold(topicos):\n",
    "            if topic_num >= len(topicos):\n",
    "                return False\n",
    "            _, valor = topicos[topic_num]\n",
    "            return valor > threshold\n",
    "\n",
    "        return self.df[self.df['topics'].apply(topic_greater_than_threshold)]['Title'].tolist()\n",
    "    \n",
    "    def Create_topics_dict(self,number_of_topics):\n",
    "        topics_dict = {}\n",
    "        text_list = self.Generate_article_text_list()\n",
    "        tokenized_list = self.Generate_tokenized_list(text_list)\n",
    "        dictionary,corpus = self.Transform_data_numeric(tokenized_list)\n",
    "        lda_model = self.Generate_lda_model(number_of_topics,corpus,dictionary,20)\n",
    "        topics_keywords = self.Get_lda_topics_keywords(lda_model)\n",
    "        self.Append_model_to_df(lda_model,corpus)\n",
    "        model_names = self.Create_model_names(topics_keywords)\n",
    "        print(model_names)\n",
    "        for i in range(number_of_topics):\n",
    "            topic_dict = {}\n",
    "            topic_name = model_names[f\"topic {i}\"]\n",
    "            topic_dict[\"name\"] = topic_name\n",
    "            articles_list = self.Get_all_titles_from_topic(i,0.95)\n",
    "            summary_prompt =(f\"\"\"\n",
    "            Topic name: {topic_name}\n",
    "            Article list: {articles_list}\n",
    "            \"\"\")\n",
    "            topic_dict[\"description\"] = self.classify_agent.Generate_summary(summary_prompt)\n",
    "            topics_dict[i] = topic_dict\n",
    "        return topics_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cec42d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759610647.962304  101145 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Topic 0': 'ISS Biomedical & Genetic Research', 'Topic 1': 'Spaceflight Genomics & Bone Health', 'Topic 2': 'Microgravity Plant & Bone Studies', 'Topic 3': 'Spaceflight Effects on Muscle & Cells', 'Topic 4': 'Model Organism Space Biology'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'topic 0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m handler = LDA_handler(\u001b[33m\"\u001b[39m\u001b[33mSB_publication_PMC.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m db_topics = \u001b[43mhandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreate_topics_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mLDA_handler.Create_topics_dict\u001b[39m\u001b[34m(self, number_of_topics)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_topics):\n\u001b[32m     63\u001b[39m     topic_dict = {}\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     topic_name = \u001b[43mmodel_names\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     65\u001b[39m     topic_dict[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] = topic_name\n\u001b[32m     66\u001b[39m     articles_list = \u001b[38;5;28mself\u001b[39m.Get_all_titles_from_topic(i,\u001b[32m0.95\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'topic 0'"
     ]
    }
   ],
   "source": [
    "handler = LDA_handler(\"SB_publication_PMC.csv\")\n",
    "db_topics = handler.Create_topics_dict(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5eee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISS Microgravity Biology explores how diverse living organisms respond and adapt to the unique conditions of the International Space Station, with a particular focus on microgravity. This research spans from the molecular level, investigating gene expression, DNA repair, and stress responses in microorganisms like *Bacillus subtilis* and *Salmonella*, to physiological changes in mammalian systems, such as bone formation and reproductive tissue health. The topic also highlights the development of specialized methodologies and technologies essential for conducting biological experiments in space, including novel systems for RNA analysis and protocols for tissue preservation. Furthermore, it delves into the adaptation of new bacterial species to space environments, utilizing advanced genomic analysis to understand their resilience and functional changes. This field ultimately seeks to unravel the fundamental biological impacts of spaceflight and advance our understanding of life beyond Earth.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_list = handler.Get_all_titles_from_topic(0,0.95)\n",
    "test_string = f\"\"\"\"\n",
    "Topic name: ISS Microgravity Biology\n",
    "articles list: {articles_list}\n",
    "\"\"\"\n",
    "\n",
    "handler.classify_agent.Generate_summary(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790edd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'name': 'topic1_name', 'description': 'minha_desc0'}, 1: {'name': 'topic2_name', 'description': 'minha_desc1'}, 2: {'name': 'topic3_name', 'description': 'minha_desc2'}, 3: {'name': 'topic4_name', 'description': 'minha_desc3'}}\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\"topic 0\":\"topic1_name\",\n",
    "           \"topic 1\":\"topic2_name\",\n",
    "           \"topic 2\":\"topic3_name\",\n",
    "           \"topic 3\":\"topic4_name\",\n",
    "           }\n",
    "\n",
    "topic_list = {}\n",
    "for i in range(4):\n",
    "    new_dict = {}\n",
    "    new_dict[\"name\"] = my_dict[f\"topic {i}\"]\n",
    "    new_dict[\"description\"] = f\"minha_desc{i}\"\n",
    "    topic_list[i] = new_dict\n",
    "\n",
    "print(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d04a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V: teste\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b979d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
