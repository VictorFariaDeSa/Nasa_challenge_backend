{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec167a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759615870.643366   24035 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "/tmp/ipykernel_24035/1291650368.py:69: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  resposta = llm([HumanMessage(content=f\"Com base nesses trechos: {textos_relevantes}, me diga quem são os autores do artigo.\")])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autores: Com base nos trechos fornecidos, **não é possível identificar os autores do artigo**. As informações sobre os autores não estão presentes nestes segmentos de texto.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# -------- Configurações --------\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "PDF_PATH = \"genes-15-00975.pdf\"\n",
    "\n",
    "# -------- Extrair texto do PDF --------\n",
    "def extrair_texto_pdf(caminho_pdf):\n",
    "    texto = \"\"\n",
    "    with pdfplumber.open(caminho_pdf) as pdf:\n",
    "        for pagina in pdf.pages:\n",
    "            texto += pagina.extract_text() + \"\\n\"\n",
    "    return texto\n",
    "\n",
    "texto = extrair_texto_pdf(PDF_PATH)\n",
    "\n",
    "# -------- Dividir texto em trechos --------\n",
    "def dividir_texto(texto, tamanho=500):\n",
    "    palavras = texto.split()\n",
    "    trechos = []\n",
    "    for i in range(0, len(palavras), tamanho):\n",
    "        trechos.append(\" \".join(palavras[i:i+tamanho]))\n",
    "    return trechos\n",
    "\n",
    "trechos = dividir_texto(texto)\n",
    "\n",
    "# -------- Gerar embeddings --------\n",
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = modelo.encode(trechos)\n",
    "\n",
    "# -------- Configurar Chroma (novo) --------\n",
    "cliente = chromadb.Client(chromadb.config.Settings(\n",
    "    persist_directory=\"meu_banco_chroma\"\n",
    "))\n",
    "\n",
    "# Cria ou pega a coleção\n",
    "if \"artigos\" in [c.name for c in cliente.list_collections()]:\n",
    "    colecao = cliente.get_collection(\"artigos\")\n",
    "else:\n",
    "    colecao = cliente.create_collection(name=\"artigos\")\n",
    "\n",
    "# -------- Inserir vetores --------\n",
    "colecao.add(\n",
    "    documents=trechos,\n",
    "    metadatas=[{\"arquivo\": PDF_PATH} for _ in trechos],\n",
    "    ids=[str(i) for i in range(len(trechos))],\n",
    "    embeddings=embeddings.tolist()\n",
    ")\n",
    "\n",
    "def buscar_autores(pergunta):\n",
    "    embedding_pergunta = modelo.encode([pergunta])\n",
    "    \n",
    "    resultados = colecao.query(\n",
    "        query_embeddings=embedding_pergunta.tolist(),\n",
    "        n_results=3\n",
    "    )\n",
    "    \n",
    "    textos_relevantes = resultados['documents'][0]\n",
    "    \n",
    "    # Gemini LLM\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", api_key=api_key)\n",
    "    resposta = llm([HumanMessage(content=f\"Com base nesses trechos: {textos_relevantes}, me diga quem são os autores do artigo.\")])\n",
    "    \n",
    "    return resposta.content\n",
    "\n",
    "# -------- Exemplo de uso --------\n",
    "pergunta = \"Quem são os autores deste artigo?\"\n",
    "autores = buscar_autores(pergunta)\n",
    "print(\"Autores:\", autores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a57d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural killer (NK) cells are an important first-line of defense against malignant cells. Because of the potential for increased cancer risk from astronaut exposure to space radiation, we determined whether microgravity present during spaceflight affects the body’s defenses against leukemogenesis. Human NK cells were cultured for 48 h under normal gravity and simulated microgravity (sμG), and cytotoxicity against K-562 (CML) and MOLT-4 (T-ALL) cells was measured using standard methodology or under continuous sμG. This brief exposure to sμG markedly reduced NK cytotoxicity against both leukemias, and these deleterious effects were more pronounced in continuous sμG. RNA-seq performed on NK cells from two additional healthy donors provided insight into the mechanism(s) by which sμG reduced cytotoxicity. Given our prior report of space radiation-induced human T-ALL in vivo, the reduced cytotoxicity against MOLT-4 is striking and raises the possibility that μG may increase astronaut risk of leukemogenesis during prolonged missions beyond LEO.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-14\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f432823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
